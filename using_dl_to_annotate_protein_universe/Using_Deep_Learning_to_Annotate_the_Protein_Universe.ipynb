{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_PsPZCvNKtI"
      },
      "source": [
        "```\n",
        "# Copyright 2021 Google Inc.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n1hzmoE9onA"
      },
      "source": [
        "# This code supports the publication \"Using Deep Learning to Annotate the Protein Universe\".\n",
        "[preprint link](https://doi.org/10.1101/626507)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX30QL0bIiPs"
      },
      "source": [
        "**Note**: We recommend you enable a free GPU by going:\n",
        "\n",
        "\u003e **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-6Ufto98_Ro"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6_SeJumHUGK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pca8JUJH9GyK"
      },
      "source": [
        "# Library functions: convert sequence to one-hot array (input to model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp-3Ccx09IJ7"
      },
      "outputs": [],
      "source": [
        "AMINO_ACID_VOCABULARY = [\n",
        "    'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R',\n",
        "    'S', 'T', 'V', 'W', 'Y'\n",
        "]\n",
        "def residues_to_one_hot(amino_acid_residues):\n",
        "  \"\"\"Given a sequence of amino acids, return one hot array.\n",
        "\n",
        "  Supports ambiguous amino acid characters B, Z, and X by distributing evenly\n",
        "  over possible values, e.g. an 'X' gets mapped to [.05, .05, ... , .05].\n",
        "\n",
        "  Supports rare amino acids by appropriately substituting. See\n",
        "  normalize_sequence_to_blosum_characters for more information.\n",
        "\n",
        "  Supports gaps and pads with the '.' and '-' characters; which are mapped to\n",
        "  the zero vector.\n",
        "\n",
        "  Args:\n",
        "    amino_acid_residues: string. consisting of characters from\n",
        "      AMINO_ACID_VOCABULARY\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of shape (len(amino_acid_residues),\n",
        "     len(AMINO_ACID_VOCABULARY)).\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if sparse_amino_acid has a character not in the vocabulary + X.\n",
        "  \"\"\"\n",
        "  to_return = []\n",
        "  normalized_residues = amino_acid_residues.replace('U', 'C').replace('O', 'X')\n",
        "  for char in normalized_residues:\n",
        "    if char in AMINO_ACID_VOCABULARY:\n",
        "      to_append = np.zeros(len(AMINO_ACID_VOCABULARY))\n",
        "      to_append[AMINO_ACID_VOCABULARY.index(char)] = 1.\n",
        "      to_return.append(to_append)\n",
        "    elif char == 'B':  # Asparagine or aspartic acid.\n",
        "      to_append = np.zeros(len(AMINO_ACID_VOCABULARY))\n",
        "      to_append[AMINO_ACID_VOCABULARY.index('D')] = .5\n",
        "      to_append[AMINO_ACID_VOCABULARY.index('N')] = .5\n",
        "      to_return.append(to_append)\n",
        "    elif char == 'Z':  # Glutamine or glutamic acid.\n",
        "      to_append = np.zeros(len(AMINO_ACID_VOCABULARY))\n",
        "      to_append[AMINO_ACID_VOCABULARY.index('E')] = .5\n",
        "      to_append[AMINO_ACID_VOCABULARY.index('Q')] = .5\n",
        "      to_return.append(to_append)\n",
        "    elif char == 'X':\n",
        "      to_return.append(\n",
        "          np.full(len(AMINO_ACID_VOCABULARY), 1. / len(AMINO_ACID_VOCABULARY)))\n",
        "    elif char == _PFAM_GAP_CHARACTER:\n",
        "      to_return.append(np.zeros(len(AMINO_ACID_VOCABULARY)))\n",
        "    else:\n",
        "      raise ValueError('Could not one-hot code character {}'.format(char))\n",
        "  return np.array(to_return)\n",
        "\n",
        "def _test_residues_to_one_hot():\n",
        "  expected = np.zeros((3, 20))\n",
        "  expected[0, 0] = 1.   # Amino acid A\n",
        "  expected[1, 1] = 1.   # Amino acid C\n",
        "  expected[2, :] = .05  # Amino acid X\n",
        "\n",
        "  actual = residues_to_one_hot('ACX')\n",
        "  np.testing.assert_allclose(actual, expected)\n",
        "_test_residues_to_one_hot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxYneKVaHxLC"
      },
      "outputs": [],
      "source": [
        "def pad_one_hot_sequence(sequence: np.ndarray,\n",
        "                         target_length: int) -\u003e np.ndarray:\n",
        "  \"\"\"Pads one hot sequence [seq_len, num_aas] in the seq_len dimension.\"\"\"\n",
        "  sequence_length = sequence.shape[0]\n",
        "  pad_length = target_length - sequence_length\n",
        "  if pad_length \u003c 0:\n",
        "    raise ValueError(\n",
        "        'Cannot set a negative amount of padding. Sequence length was {}, target_length was {}.'\n",
        "        .format(sequence_length, target_length))\n",
        "  pad_values = [[0, pad_length], [0, 0]]\n",
        "  return np.pad(sequence, pad_values, mode='constant')\n",
        "\n",
        "def _test_pad_one_hot():\n",
        "  input_one_hot = residues_to_one_hot('ACX')\n",
        "  expected = np.array(input_one_hot.tolist() + np.zeros((4, 20)).tolist())\n",
        "  actual = pad_one_hot_sequence(input_one_hot, 7)\n",
        "\n",
        "  np.testing.assert_allclose(expected, actual)\n",
        "_test_pad_one_hot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egM-2RHJ9Bnm"
      },
      "source": [
        "# Download model and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3233,
          "status": "ok",
          "timestamp": 1622643790693,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "Up68255TDGKe",
        "outputId": "a50f7057-c1ef-494c-f6aa-ff1b33e11978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-06-02 14:23:10--  https://storage.googleapis.com/brain-genomics-public/research/proteins/pfam/models/single_domain_per_sequence_zipped_models/trained_model_pfam_32.0_vocab.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.119.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 197219 (193K) [application/octet-stream]\n",
            "Saving to: ‘trained_model_pfam_32.0_vocab.json.2’\n",
            "\n",
            "\r          trained_m   0%[                    ]       0  --.-KB/s               \rtrained_model_pfam_ 100%[===================\u003e] 192.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-06-02 14:23:10 (131 MB/s) - ‘trained_model_pfam_32.0_vocab.json.2’ saved [197219/197219]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a TensorFlow SavedModel\n",
        "!wget -qN https://storage.googleapis.com/brain-genomics-public/research/proteins/pfam/models/single_domain_per_sequence_zipped_models/seed_random_32.0/5356760.tar.gz\n",
        "# unzip\n",
        "!tar xzf 5356760.tar.gz\n",
        "# Get the vocabulary for the model, which tells you which output index means which family\n",
        "!wget https://storage.googleapis.com/brain-genomics-public/research/proteins/pfam/models/single_domain_per_sequence_zipped_models/trained_model_pfam_32.0_vocab.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1622643790694,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "XM3H7Y-rGPg8",
        "outputId": "4d71b1ef-0c73-4662-9dd1-4f9669da88a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5356760.tar.gz\n",
            "\n",
            "trn-_cnn_random__random_sp_gpu-cnn_for_random_pfam-5356760:\n",
            "saved_model.pb\tvariables\n"
          ]
        }
      ],
      "source": [
        "# Find the unzipped path\n",
        "!ls *5356760*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYaOgeZx9JrV"
      },
      "source": [
        "# Load the model into TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp1imZTA6L_0"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "graph = tf.Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbZfobaq6bkI"
      },
      "outputs": [],
      "source": [
        "with graph.as_default():\n",
        "  saved_model = tf.saved_model.load(sess, ['serve'], 'trn-_cnn_random__random_sp_gpu-cnn_for_random_pfam-5356760')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR0Gl4Mx9Mgm"
      },
      "source": [
        "## Load tensors for class confidence prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbapL8YS7FpE"
      },
      "outputs": [],
      "source": [
        "class_confidence_signature = saved_model.signature_def['confidences']\n",
        "class_confidence_signature_tensor_name = list(class_confidence_signature.outputs.values())[0].name\n",
        "\n",
        "sequence_input_tensor_name = list(saved_model.signature_def['confidences'].inputs.values())[0].name\n",
        "sequence_lengths_input_tensor_name = list(saved_model.signature_def['confidences'].inputs.values())[1].name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9iUCIO99QPs"
      },
      "source": [
        "# Run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB_fZuxm8KL8"
      },
      "outputs": [],
      "source": [
        "# Run inference\n",
        "hemoglobin = 'MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHGKKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTPAVHASLDKFLASVSTVLTSKYR'\n",
        "globin_domain = hemoglobin[6:107]  # 0-indexed, right inclusive because of the way slices in python work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ1_wLxE7SeS"
      },
      "outputs": [],
      "source": [
        "# The first run of this cell will be slower; the subsequent runs will be fast.\n",
        "# This is because on the first run, the TensorFlow XLA graph is compiled, and\n",
        "# then is reused.\n",
        "with graph.as_default():\n",
        "  confidences_by_class = sess.run(\n",
        "      class_confidence_signature_tensor_name,\n",
        "      {\n",
        "          # Note that this function accepts a batch of sequences which\n",
        "          # can speed up inference when running on many sequences.\n",
        "          sequence_input_tensor_name: [residues_to_one_hot(globin_domain)],\n",
        "          sequence_lengths_input_tensor_name: [len(globin_domain)],\n",
        "      }\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1622643832634,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "w0D54NI18z0p",
        "outputId": "52b56396-61d0-4744-eae3-8bab5ecb80c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.7192134e-20, 4.8992849e-21, 3.2679127e-21, ..., 1.8260855e-19,\n",
              "        1.8321699e-19, 1.8437245e-19]], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confidences_by_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BMjr7rr9TBt"
      },
      "source": [
        "## Look up inference result in vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV6kx-97GIz6"
      },
      "outputs": [],
      "source": [
        "# Load vocab\n",
        "with open('trained_model_pfam_32.0_vocab.json') as f:\n",
        "  vocab = json.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 763,
          "status": "ok",
          "timestamp": 1622643847821,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "N4rw5aUzGw18",
        "outputId": "d3e10293-3d3d-437e-b8a9-c5f518c5b0b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8505"
            ]
          },
          "execution_count": 21,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find what the most likely class is\n",
        "np.argmax(confidences_by_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1622643847822,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "EyKlb172GyJW",
        "outputId": "36aebb1d-f141-49b5-8945-6b3c0091ce78"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PF00042'"
            ]
          },
          "execution_count": 22,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab[8505] # PF00042 is family Globin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSJ-lE1rFpFi"
      },
      "source": [
        "## Run inference on a batch of sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "executionInfo": {
          "elapsed": 256,
          "status": "ok",
          "timestamp": 1622644597045,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "SxMgmERaJ0UR",
        "outputId": "0afb322a-4582-4527-e926-b7e9fd60db56"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIM'"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'[709:1233]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lnmm-4eFpFj"
      },
      "outputs": [],
      "source": [
        "# Run inference\n",
        "\n",
        "hemoglobin = 'MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHGKKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTPAVHASLDKFLASVSTVLTSKYR'\n",
        "globin_domain = hemoglobin[6:107]  # 0-indexed, right inclusive because of the way slices in python work\n",
        "\n",
        "# Coronavirus spike glycoprotein S2 (PF01601)\n",
        "covid_spike_protein_domain = \"NSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIM\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QeV--uMIzIk"
      },
      "outputs": [],
      "source": [
        "# Concatenate and pad sequence inputs\n",
        "one_hot_sequence_inputs = [\n",
        "              residues_to_one_hot(globin_domain),\n",
        "              residues_to_one_hot(covid_spike_protein_domain),\n",
        "]\n",
        "\n",
        "max_len_within_batch = max(len(globin_domain), len(covid_spike_protein_domain))\n",
        "padded_sequence_inputs = [pad_one_hot_sequence(s, max_len_within_batch)\n",
        "                          for s in one_hot_sequence_inputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpquKRJoFpFj"
      },
      "outputs": [],
      "source": [
        "# The first run of this cell will be slower; the subsequent runs will be fast.\n",
        "# This is because on the first run, the TensorFlow XLA graph is compiled, and\n",
        "# then is reused.\n",
        "with graph.as_default():\n",
        "  confidences_by_class = sess.run(\n",
        "      class_confidence_signature_tensor_name,\n",
        "      {\n",
        "          sequence_input_tensor_name: padded_sequence_inputs,\n",
        "          sequence_lengths_input_tensor_name: [\n",
        "              len(globin_domain),\n",
        "              len(covid_spike_protein_domain)\n",
        "          ],\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1622644635776,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "uO7jvH-dFpFk",
        "outputId": "68b6cb97-e925-4cb4-9819-b5fce8b678c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PF00042'"
            ]
          },
          "execution_count": 47,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab[np.argmax(confidences_by_class[0])] # 0th element is for hemoglobin; PF00042 is family Globin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "elapsed": 276,
          "status": "ok",
          "timestamp": 1622644653944,
          "user": {
            "displayName": "Max Bileschi",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GitXIykR1gtlBRIs-bPZf_D4a9ImDClhflCtXp0hw=s64",
            "userId": "14775344795310750645"
          },
          "user_tz": 240
        },
        "id": "cNNAyMa9Jhlp",
        "outputId": "c7ada5b7-6c68-4ab0-b072-90a46c15ccf4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PF01601'"
            ]
          },
          "execution_count": 49,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab[np.argmax(confidences_by_class[1])] # 1th element is for covid; PF01601 is Coronavirus spike glycoprotein S2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCd4yMbSFpFk"
      },
      "source": [
        "## Look up inference result in vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KFQLCUjFpFl"
      },
      "outputs": [],
      "source": [
        "# Load vocab\n",
        "with open('trained_model_pfam_32.0_vocab.json') as f:\n",
        "  vocab = json.loads(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5t-BFQzFpFl",
        "outputId": "f4a2e588-b2c1-4847-b460-27090bd17c25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8505"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find what the most likely class is\n",
        "np.argmax(confidences_by_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2lHNTAZQFpFl",
        "outputId": "e77b0055-02c4-4fd1-8431-63fab07aa190"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PF00042'"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab[8505] # PF00042 is family Globin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-e-xWYw9Uzl"
      },
      "source": [
        "# Compute embedding of domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FRCNv3G9-hw"
      },
      "outputs": [],
      "source": [
        "embedding_signature = saved_model.signature_def['pooled_representation']\n",
        "embedding_signature_tensor_name = list(embedding_signature.outputs.values())[0].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfh4JW3x9-h9"
      },
      "outputs": [],
      "source": [
        "# The first run of this cell will be slower; the subsequent runs will be fast.\n",
        "# This is because on the first run, the TensorFlow XLA graph is compiled, and\n",
        "# then is reused.\n",
        "with graph.as_default():\n",
        "  embedding = sess.run(\n",
        "      embedding_signature_tensor_name,\n",
        "      {\n",
        "          # Note that this function accepts a batch of sequences which\n",
        "          # can speed up inference when running on many sequences.\n",
        "          sequence_input_tensor_name: [residues_to_one_hot(globin_domain)],\n",
        "          sequence_lengths_input_tensor_name: [len(globin_domain)],\n",
        "      }\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJRKUEwI89JR",
        "outputId": "8e246daf-7258-44ea-9ca1-bc7254054f36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1100)"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shape of embedding is (# seqs in batch, number of features in embedding space)\n",
        "embedding.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v-6Ufto98_Ro",
        "Pca8JUJH9GyK",
        "egM-2RHJ9Bnm",
        "MYaOgeZx9JrV",
        "IR0Gl4Mx9Mgm",
        "p9iUCIO99QPs",
        "_BMjr7rr9TBt",
        "CSJ-lE1rFpFi",
        "MCd4yMbSFpFk",
        "P-e-xWYw9Uzl"
      ],
      "name": "Using Deep Learning to Annotate the Protein Universe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
